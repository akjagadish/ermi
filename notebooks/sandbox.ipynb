{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6d002d22-84b8-4b67-90d7-24846c954c43",
   "metadata": {},
   "source": [
    "!pip install --upgrade Pillow mycolorpy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35965d45-eaba-4323-a029-38fc12349381",
   "metadata": {},
   "source": [
    "path_to_init_weights = '/u/ajagadish/ermi/decisionmaking/trained_models/env=claude_dim2_model=transformer_num_episodes100000_num_hidden=256_lr0.1_num_layers=6_d_model=64_num_head=8_noise0.0_shuffleTrue_pairedTrue_lossvariational_ess150000_std0.1_run=0.pt'\n",
    "# t, model = torch.load(path_to_init_weights)\n",
    "state_dict = torch.load(\n",
    "    path_to_init_weights, map_location=torch.device('cpu'))[1]\n",
    "# model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d37f511-ccf0-4a4e-98d8-487a7c291d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "991c779c-829a-4214-84b6-f4c9906c49e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/u/ajagadish/ermi/categorisation/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from wordcloud import WordCloud\n",
    "from mycolorpy import colorlist as mcp\n",
    "import math\n",
    "FONTSIZE=20\n",
    "SYS_PATH = '/u/ajagadish/ermi' #'/raven/u/ajagadish/vanilla-llama/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e382512b-7ac5-47a8-8b65-54cdf57c3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_data = pd.read_csv('/u/ajagadish/ermi/decisionmaking/data/claude_generated_functionlearningtasks_paramsNA_dim2_data20_tasks9254_run0_procid0_pversion2_unknown.csv')\n",
    "df_features = pd.read_csv('/u/ajagadish/ermi/decisionmaking/data/synthesize_problems/claude_synthesized_functionlearning_problems_paramsNA_dim2_tasks9254_pversion0.csv')\n",
    "df_combined = pd.read_csv('/u/ajagadish/ermi/decisionmaking/data/claude_generated_functionlearningtasks_paramsNA_dim2_data20_tasks9254_run0_procid0_pversion2_unknown.csv')\n",
    "\n",
    "features = []\n",
    "targets = []\n",
    "for task_id in df_data.task_id.values:\n",
    "    feature_name = eval(df_features[df_features.task_id==task_id].feature_names.values[0])\n",
    "    target_name =  df_features[df_features.task_id==task_id].target_names.values\n",
    "    features.append(feature_name)\n",
    "    targets.append(target_name)\n",
    "df_combined.insert(2, 'feature_names', features)\n",
    "df_combined.insert(3, 'target_names', targets)\n",
    "\n",
    "df_combined.to_csv('/u/ajagadish/ermi/decisionmaking/data/combined/claude_generated_functionlearningtasks_paramsNA_dim2_data20_tasks9254_run0_procid0_pversion2_unknown.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfe88b9e-ad70-490d-a9db-2b6ef55bbc1b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "db642577-ce90-4ab3-9192-baabcbbbd181",
   "metadata": {},
   "source": [
    "datasets = torch.load('/u/ajagadish/ermi/decisionmaking/data/dataset_torch.pth')\n",
    "# dataset is organised as a list of tuples (X,y) where X is a torch tensor of shape (n_samples, n_features) and y is a torch tensor of shape (n_samples,)\n",
    "for (X,y) in datasets:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "# save this as a pandas dataframe with  two coloumns 'input', 'target' and 'trial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe34543-b294-4cd7-abb2-f2e2299580a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../decisionmaking/data/stats/stats_0_4_direction.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../decisionmaking/data/stats/stats_0_4_direction.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m coeffs \u001b[38;5;241m=\u001b[39m stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirection_coeff\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(np\u001b[38;5;241m.\u001b[39margmax(coeffs,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), bins\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m, density\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/eris/scratch/ajagadish/conda-envs/pytorch-gpu/lib/python3.9/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../decisionmaking/data/stats/stats_0_4_direction.npz'"
     ]
    }
   ],
   "source": [
    "stats = np.load('../decisionmaking/data/stats/stats_0_4_direction.npz')\n",
    "coeffs = stats['direction_coeff']\n",
    "plt.hist(np.argmax(coeffs,axis=1), bins=np.arange(5)-0.5, density=True)\n",
    "# print((coeffs>=0).sum()/coeffs.size)\n",
    "print(f\"M={stats['sign_coeff'].mean()}, SE={np.round(stats['sign_coeff'].std()/len(stats['sign_coeff']),4)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "139d12da-63a7-47d1-97b0-df24a1a3e498",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3ea7b9-ff7a-4618-84d5-6ac3455104f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = np.load('../decisionmaking/data/stats/stats_0_4_ranked.npz')\n",
    "coeffs = stats['direction_coeff']\n",
    "plt.hist(np.argmax(coeffs,axis=1), bins=np.arange(5)-0.5, density=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea101154-2fbc-44cc-8b7e-640ce19b719b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc728b58-48ed-4308-a965-ce0285417115",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = np.load('../decisionmaking/data/stats/stats_0_4_ranked.npz')\n",
    "coeffs = stats['direction_coeff']\n",
    "plt.hist(np.argmax(coeffs,axis=1), bins=np.arange(5)-0.5, density=True)\n",
    "# print((coeffs>=0).sum()/coeffs.size)\n",
    "print(f\"M={stats['sign_coeff'].mean()}, SE={np.round(stats['sign_coeff'].std()/len(stats['sign_coeff']),4)}\")\n",
    "\n",
    "stats = np.load('../decisionmaking/data/stats/stats_0_4_direction.npz')\n",
    "coeffs = stats['direction_coeff']\n",
    "plt.hist(np.argmax(coeffs,axis=1), bins=np.arange(5)-0.5, density=True);"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad902ef6-a229-46ee-b7b1-19a1857cf5f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2bc891-3a4e-46b9-a0f8-ba2d469d85e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load('../decisionmaking/data/model_comparison/binz2022_env=claude_generated_functionlearningtasks_paramsNA_dim2_data20_tasks9254_run0_procid0_pversion2_model=transformer_num_episodes100000_num_hidden=256_lr0.0003_num_layers=6_d_model=64_num_head=8_noise0._soft_sigmoid_differential_evolution.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c10f35-434f-4860-a3dd-ab57a0c36073",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ERMI fit to Binz2022: pseudo-R2 {results['pr2s'].mean()}, fitted betas {results['betas'].mean()}, model accuracy with fitted betas {results['accs'].mean()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83204f96-5ca0-4106-bf5f-065a48c22543",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['accs'][results['betas'].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc052520-168a-4f26-b1f1-a1cc9fb4150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['betas']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c129a354-b536-4750-ac3f-ee905d315c90",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e44121f-382e-4069-8d78-6430cfc12614",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = np.asarray([[0.        , 0.72946176],\n",
    "       [0.71636364, 1.        ],\n",
    "       [0.70545454, 0.85694051],\n",
    "       [0.03151515, 0.        ],\n",
    "       [1.        , 0.25070821],\n",
    "       [0.6169697 , 0.4674221 ],\n",
    "       [0.84242424, 0.71246459],\n",
    "       [0.79878788, 0.6388102 ],\n",
    "       [0.99030303, 0.00141643],\n",
    "       [0.59272727, 0.4815864 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d21c5a-4dc4-4685-b41a-ca583c43132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = np.asarray([[-385.,  -31.],\n",
    "       [ 206.,  160.],\n",
    "       [ 197.,   59.],\n",
    "       [-359., -546.],\n",
    "       [ 440., -369.],\n",
    "       [ 124., -216.],\n",
    "       [ 310.,  -43.],\n",
    "       [ 274.,  -95.],\n",
    "       [ 432., -545.],\n",
    "       [ 104., -206.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe1292-88cf-47fe-8ee0-f9a149ea7d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = np.asarray([[0.0837, 0.7804, 0.0000],\n",
    "        [0.8221, 0.8259, 0.0000],\n",
    "        [0.9325, 0.0000, 0.0000],\n",
    "        [0.8216, 0.7341, 0.0000],\n",
    "        [0.7704, 0.8652, 0.0000],\n",
    "        [0.0000, 0.8905, 0.0000],\n",
    "        [0.5395, 1.0000, 0.0000],\n",
    "        [0.4044, 0.8787, 0.0000],\n",
    "        [0.2575, 0.9541, 0.0000],\n",
    "        [1.0000, 0.8560, 0.0000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f324e3-0aa9-4457-92ee-3722ef64ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = np.asarray([[1.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [1.],\n",
    "        [0.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f4e24-ee12-4467-b4c3-9e119b9e1ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(bb[:,0], bb[:,1], c=cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b461c-5a53-41f2-a999-05df20648bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa='/u/ajagadish/ermi/decisionmaking/data/model_comparison/binz2022_env=claude_generated_functionlearningtasks_paramsNA_dim2_data20_tasks9254_run0_procid0_pversion2_model=transformer_num_episodes100000_num_hidden=256_lr0.0003_num_layers=6_d_model=64_num_head=8_noise0.0_shuffleTrue_run=0_test_soft_sigmoid_differential_evolution.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a64259-4245-4bd1-92e9-a32fbab6624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d624e57-ce15-4d1c-a0cf-20bea0219a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e61d9c-a36c-45cc-ad88-b2e585504ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf19d8-8855-4461-afbf-869316fb9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_normalized(data):\n",
    "            data = np.stack(data)\n",
    "            return (data - data.min())/(data.max() - data.min() + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5838a-6da6-40e1-9619-b9628900b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = stacked_normalized(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfbe97d-d0ea-44cf-8f38-cfeb23b5f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(cc[:,0], cc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715f1cf2-fb0b-49bf-ae51-c1ac22f969c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dd[:,0], dd[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292dc48b-9840-4d4f-a1ec-b8817071458b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ce28c-0999-4700-8390-2e1ba7e7ce17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616caceb-69e2-41eb-9d4e-ebb81e903f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Compute the difference along dimension 0\n",
    "diff_dim0 = torch.diff(tensor, dim=1)\n",
    "print(diff_dim0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc33b79-d545-4ebd-a39a-5ad0a3dd1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_dim0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2055c481-bb74-4df3-8bce-10104ecab942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def world_cloud(file_name, path='/u/ajagadish/ermi/decisionmaking/data/synthesize_problems', feature_names=True, pairs=False, top_labels=50):\n",
    "\n",
    "    df = pd.read_csv(f'{path}/{file_name}.csv')\n",
    "    dim = int(file_name.split(\"_dim\")[1].split(\"_\")[0])\n",
    "    df.feature_names = df['feature_names'].apply(lambda x: list(eval(x)[:dim]))\n",
    "    def to_lower(ff):\n",
    "        return [x.lower() for x in ff]\n",
    "\n",
    "    # name of the column containing the feature names\n",
    "    column_name = 'feature_names' if feature_names else 'target_names'\n",
    "    # count of number of times a type of features occurs\n",
    "    list_counts = Counter([tuple(features) for features in df[column_name]] if pairs else np.stack(df[column_name].values).reshape(-1))\n",
    "\n",
    "    # sort the Counter by counts in descending order\n",
    "    sorted_list_counts = sorted(list_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # extract the counts and names for the top 50 labels\n",
    "    task_labels = np.array([task_label[0] for task_label in sorted_list_counts[:top_labels]])\n",
    "    label_counts= np.array([task_label[1] for task_label in sorted_list_counts[:top_labels]])\n",
    "    label_names = ['-'.join(task_labels[idx]) for idx in range(len(task_labels))] if pairs else task_labels\n",
    "\n",
    "    # make a dict with task labels and counts\n",
    "    word_freq = {}\n",
    "    for idx in range(len(label_names)):\n",
    "        word_freq[label_names[idx]] = label_counts[idx]\n",
    "\n",
    "    # generate word cloud\n",
    "    # wordcloud = WordCloud(width=800, height=400, max_words=50, background_color='white').generate_from_frequencies(word_freq)\n",
    "    wordcloud = WordCloud(width = 1300, height = 700, background_color='white',max_font_size = 100, collocations=False, colormap='inferno', prefer_horizontal=1).generate_from_frequencies(word_freq)\n",
    "    plt.figure(figsize=(13, 7), dpi=1000)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    wordcloud.to_file(f'{SYS_PATH}/figures/wordcloud_{column_name}_paired={pairs}_top{top_labels}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b01640-e09e-49d1-9fbd-e147ea311c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#world_cloud('claude_synthesized_functionlearning_problems_paramsNA_dim1_tasks9991_pversion0', feature_names=False, pairs=False)\n",
    "world_cloud('claude_synthesized_functionlearning_problems_paramsNA_dim2_tasks9254_pversion0', feature_names=True, pairs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69332a8b-bbe8-4017-b812-f480525bf16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d3bbb-51d6-409a-9ff0-46eb43f4f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def world_cloud(file_name, path='/u/ajagadish/vanilla-llama/categorisation/data/tasklabels', feature_names=True, pairs=False, top_labels=50):\n",
    "\n",
    "    df = pd.read_csv(f'{path}/{file_name}.csv')\n",
    "    df.feature_names = df['feature_names'].apply(lambda x: eval(x))\n",
    "    df.category_names = df['category_names'].apply(lambda x: eval(x))\n",
    "    \n",
    "    def to_lower(ff):\n",
    "        return [x.lower() for x in ff]\n",
    "    \n",
    "    df.feature_names = df['feature_names'].apply(lambda x: to_lower(x))\n",
    "    df.category_names = df['category_names'].apply(lambda x: to_lower(x))\n",
    "\n",
    "    # name of the column containing the feature names\n",
    "    column_name = 'feature_names' if feature_names else 'category_names'\n",
    "    # count of number of times a type of features occurs\n",
    "    list_counts = Counter([tuple(features) for features in df[column_name]] if pairs else np.stack(df[column_name].values).reshape(-1))\n",
    "\n",
    "    # sort the Counter by counts in descending order\n",
    "    sorted_list_counts = sorted(list_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # extract the counts and names for the top 50 labels\n",
    "    task_labels = np.array([task_label[0] for task_label in sorted_list_counts[:top_labels]])\n",
    "    label_counts= np.array([task_label[1] for task_label in sorted_list_counts[:top_labels]])\n",
    "    label_names = ['-'.join(task_labels[idx]) for idx in range(len(task_labels))] if pairs else task_labels\n",
    "\n",
    "    # make a dict with task labels and counts\n",
    "    word_freq = {}\n",
    "    for idx in range(len(label_names)):\n",
    "        word_freq[label_names[idx]] = label_counts[idx]\n",
    "\n",
    "    # generate word cloud\n",
    "    # wordcloud = WordCloud(width=800, height=400, max_words=50, background_color='white').generate_from_frequencies(word_freq)\n",
    "    wordcloud = WordCloud(width = 1300, height = 700, background_color='white',max_font_size = 100, collocations=False, colormap='inferno', prefer_horizontal=1).generate_from_frequencies(word_freq)\n",
    "    plt.figure(figsize=(13, 7), dpi=1000)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    wordcloud.to_file(f'{SYS_PATH}/figures/wordcloud_{column_name}_paired={pairs}_top{top_labels}.png')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b537a64-0809-49e7-a644-8894848170fc",
   "metadata": {},
   "source": [
    "world_cloud('claude_generated_tasklabels_paramsNA_dim3_tasks23421_pversion5', feature_names=False, pairs=False)\n",
    "world_cloud('claude_generated_tasklabels_paramsNA_dim3_tasks23421_pversion5', feature_names=True, pairs=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "379c65e7-d986-4308-b065-31094a7c4de0",
   "metadata": {},
   "source": [
    "world_cloud('claude_generated_tasklabels_paramsNA_dim4_tasks20690_pversion5', feature_names=False, pairs=False)\n",
    "world_cloud('claude_generated_tasklabels_paramsNA_dim4_tasks20690_pversion5', feature_names=True, pairs=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9990a2c-4079-462f-b020-0f5447792fee",
   "metadata": {},
   "source": [
    "world_cloud('claude_generated_tasklabels_paramsNA_dim6_tasks13693_pversion5', feature_names=False, pairs=False)\n",
    "world_cloud('claude_generated_tasklabels_paramsNA_dim6_tasks13693_pversion5', feature_names=True, pairs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23cc4b9-530a-4e51-be18-80d7a390c6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef86c84e-be20-4f18-b79a-a4a603fc31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frequency_tasklabels(file_name, path='/u/ajagadish/vanilla-llama/categorisation/data/tasklabels', feature_names=True, pairs=True, top_labels=50):\n",
    "\n",
    "    df = pd.read_csv(f'{path}/{file_name}.csv')\n",
    "    df.feature_names = df['feature_names'].apply(lambda x: eval(x))\n",
    "    df.category_names = df['category_names'].apply(lambda x: eval(x))\n",
    "    \n",
    "    def to_lower(ff):\n",
    "        return [x.lower() for x in ff]\n",
    "    \n",
    "    df.feature_names = df['feature_names'].apply(lambda x: to_lower(x))\n",
    "    df.category_names = df['category_names'].apply(lambda x: to_lower(x))\n",
    "\n",
    "    # name of the column containing the feature names\n",
    "    column_name = 'feature_names' if feature_names else 'category_names'\n",
    "    # count of number of times a type of features occurs\n",
    "    list_counts = Counter([tuple(features) for features in df[column_name]] if pairs else np.stack(df[column_name].values).reshape(-1))\n",
    "\n",
    "    # sort the Counter by counts in descending order\n",
    "    sorted_list_counts = sorted(list_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # extract the counts and names for the top 50 labels\n",
    "    task_labels = np.array([task_label[0] for task_label in sorted_list_counts[:top_labels]])\n",
    "    label_counts= np.array([task_label[1] for task_label in sorted_list_counts[:top_labels]])\n",
    "    label_names = ['-'.join(task_labels[idx]) for idx in range(len(task_labels))] if pairs else task_labels\n",
    "\n",
    "    # plot the bars of labels and counts\n",
    "    f, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "    ax.bar(label_names, label_counts)\n",
    "    plt.xticks(label_names, label_names, rotation=90, fontsize=FONTSIZE-6.5)\n",
    "    plt.yticks(fontsize=FONTSIZE-6)\n",
    "    ax.set_xlabel('Feature Names' if feature_names else 'Category Names', fontsize=FONTSIZE)\n",
    "    ax.set_ylabel('Counts', fontsize=FONTSIZE)\n",
    "    ax.set_title(f'Top {top_labels} Tasks', fontsize=FONTSIZE)\n",
    "    sns.despine()\n",
    "    f.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    f.savefig(f'{SYS_PATH}/figures/frequency_plot_tasklabels_{column_name}_paired={pairs}_top{top_labels}.png', bbox_inches='tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3ea2855-877a-4513-b33a-2a03af0484c7",
   "metadata": {},
   "source": [
    "plot_frequency_tasklabels('claude_generated_tasklabels_paramsNA_dim3_tasks23421_pversion5', feature_names=False, pairs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac906bd5-9960-4f0c-8801-7adedb4159a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7da25-ae13-484b-864e-0f219561bbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b0645f-177e-4765-9be2-f2b9839f2764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_simulations_smith1998(plot='main'):\n",
    "\n",
    "    models = ['smith1998', 'ermi', 'synthetic', 'llm'] if plot == 'main' else ['smith1998', 'ermi', 'syntheticnonlinear']#'human'\n",
    "    f, ax = plt.subplots(1, len(models), figsize=(5*len(models),5))\n",
    "    colors = ['#173b4f', '#748995']##5d7684']\n",
    "    # colors = ['#173b4f', '#4d6a75', '#5d7684', '#748995','#4d6a75', '#0d2c3d', '#a2c0a9', '#2f4a5a', '#8b9da7']\n",
    "    num_blocks = None\n",
    "    for idx, model in enumerate(models):\n",
    "        if model=='smith1998':\n",
    "       \n",
    "            with open(f'{SYS_PATH}/categorisation/data/human/{model}.json') as file:\n",
    "                human_data = json.load(file)\n",
    "\n",
    "            # human data procesing\n",
    "            fits_gcm, fits_pm = {}, {}\n",
    "            mses_gcm = np.array(human_data['exemplar']['y'])\n",
    "            mses_pm = np.array(human_data['prototype']['y'])\n",
    "            # std error of mean across participants set to 0.\n",
    "            stds_gcm = np.zeros_like(mses_gcm)\n",
    "            stds_pm = np.zeros_like(mses_pm)\n",
    "            # unsquezze to add a dimension for participants\n",
    "            mses_gcm = np.expand_dims(mses_gcm, axis=0)\n",
    "            mses_pm = np.expand_dims(mses_pm, axis=0)\n",
    "    \n",
    "        else:\n",
    "\n",
    "            fits_gcm = np.load(f'{SYS_PATH}/categorisation/data/fitted_simulation/devraj2022_gcm_runs=1_iters=1_blocks=11_loss=mse_transfer_model={model}.npz')\n",
    "            fits_pm = np.load(f'{SYS_PATH}/categorisation/data/fitted_simulation/devraj2022_pm_runs=1_iters=1_blocks=11_loss=mse_transfer_model={model}.npz')\n",
    "            \n",
    "            # load mses\n",
    "            mses_gcm = fits_gcm['lls']\n",
    "            mses_pm = fits_pm['lls']\n",
    "            # mean mses across participants: mses are of shape (n_runs=1, n_participants, n_conditions=1, n_blocks)\n",
    "            mses_gcm = np.squeeze(mses_gcm)\n",
    "            mses_pm = np.squeeze(mses_pm)\n",
    "            # std error of mean across participants\n",
    "            stds_gcm = np.std(mses_gcm, axis=0)/np.sqrt(len(mses_gcm)-1)\n",
    "            stds_pm = np.std(mses_pm, axis=0)/np.sqrt(len(mses_pm)-1)\n",
    "             \n",
    "        # keep only the first num_blocks (useful when using smith1998 data)\n",
    "        num_blocks = 10 if 'smith1998' in models else 33\n",
    "        mses_gcm = mses_gcm[:, :num_blocks]\n",
    "        mses_pm = mses_pm[:, :num_blocks]\n",
    "        stds_gcm = stds_gcm[:num_blocks]\n",
    "        stds_pm = stds_pm[:num_blocks]\n",
    "    \n",
    "        # plot mean mses across participants for each trial segment for both models\n",
    "        sns.lineplot(x=np.arange(mses_pm.shape[1])+1, y=np.mean(mses_pm, axis=0), ax=ax[idx], color=colors[0], label='Protype-based', lw=3)\n",
    "        sns.lineplot(x=np.arange(mses_gcm.shape[1])+1, y=np.mean(mses_gcm, axis=0), ax=ax[idx], color=colors[1], label='Exemplar-based', lw=3)\n",
    "        # add standard error of mean as error bars\n",
    "        ax[idx].fill_between(np.arange(mses_pm.shape[1])+1, np.mean(mses_pm, axis=0)-stds_pm, np.mean(mses_pm, axis=0)+stds_pm, alpha=0.2, color=colors[0])\n",
    "        ax[idx].fill_between(np.arange(mses_gcm.shape[1])+1, np.mean(mses_gcm, axis=0)-stds_gcm, np.mean(mses_gcm, axis=0)+stds_gcm, alpha=0.2, color=colors[1])\n",
    "        ax[idx].set_ylim([-0.05, 3.])\n",
    "        ax[idx].set_xticks(np.arange(mses_gcm.shape[1])+1)\n",
    "        # set y ticks font size\n",
    "        ax[idx].tick_params(axis='y', labelsize=FONTSIZE-2)\n",
    "        ax[idx].set_xticklabels(np.arange(mses_gcm.shape[1])+1,fontsize=FONTSIZE-2)\n",
    "        if idx==0:\n",
    "            ax[idx].set_ylabel('Error', fontsize=FONTSIZE)\n",
    "            # remove bounding box around the legend\n",
    "            ax[idx].legend(frameon=False, fontsize=FONTSIZE-2)\n",
    "            ax[idx].set_title('Human', fontsize=FONTSIZE)\n",
    "            ax[idx].set_xlabel('Block', fontsize=FONTSIZE) #Trial segment\n",
    "        elif idx==1:\n",
    "            ax[idx].set_title('ERMI', fontsize=FONTSIZE)\n",
    "        elif idx==2:\n",
    "            ax[idx].set_title('MI' if plot == \"main\" else 'PFN', fontsize=FONTSIZE)\n",
    "        elif idx==3:\n",
    "            ax[idx].set_title('LLM' if plot == \"main\" else 'PFN', fontsize=FONTSIZE)\n",
    "            \n",
    "        \n",
    "        if idx!=0:\n",
    "            # remove legend\n",
    "            ax[idx].legend([], frameon=False, fontsize=FONTSIZE-2)\n",
    "        \n",
    "    sns.despine()\n",
    "    f.tight_layout()\n",
    "    plt.show()\n",
    "    f.savefig(f'{SYS_PATH}/figures/model_simulations_smith1998.png', bbox_inches='tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87f8b3-8ee4-4f11-a85b-950d023bc91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simulations_smith1998('main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ab678-cabd-45ed-9a98-b834332ee06a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e4848-9967-469e-a2bd-91808dfd6963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groupBMC.groupBMC import GroupBMC\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "mean_performance = pd.read_csv('../categorisation/data/openMLCC18/mean_performance.csv')\n",
    "LogEvidence = mean_performance.values[:, 1:-1].T\n",
    "result = GroupBMC(LogEvidence).get_result()\n",
    "\n",
    "models = list(mean_performance.columns.values[1:-1])\n",
    "models[0] = 'Logistic \\n Regression'\n",
    "# rename models for plot\n",
    "colors = ['#173b4f', '#8b9da7', '#5d7684', '#2f4a5a', '#0d2c3d', '#4d6a75', '#748995', '#a2c0a9', '#c4d9c2']\n",
    "# sort result in descending order\n",
    "sort_order = np.argsort(result.exceedance_probability)[::-1]\n",
    "result.exceedance_probability = result.exceedance_probability[sort_order]\n",
    "models = np.array(models)[sort_order]\n",
    "colors = np.array(colors)[sort_order]\n",
    "FIGSIZE=(7.5,5)\n",
    "FONTSIZE=20\n",
    "horizontal = False\n",
    "f, ax = plt.subplots(1, 1, figsize=FIGSIZE)\n",
    "if horizontal:\n",
    "    # composed\n",
    "    ax.barh(np.arange(len(models)), result.exceedance_probability, align='center', color=colors[:len(models)], height=0.6)#, hatch='//', label='Compostional Subtask')\n",
    "    # plt.legend(fontsize=FONTSIZE-4, frameon=False)\n",
    "    ax.set_ylabel('Models', fontsize=FONTSIZE)\n",
    "    # ax.set_xlim(0, 0.7)\n",
    "    ax.set_xlabel('Exceedance probability', fontsize=FONTSIZE) \n",
    "    plt.yticks(ticks=np.arange(len(models)), labels=models, fontsize=FONTSIZE-3.)\n",
    "    # ax.set_xticks(np.arange(0, result.exceedance_probability.max(), 0.1))\n",
    "    plt.xticks(fontsize=FONTSIZE-4)\n",
    "else:\n",
    "    # composed\n",
    "    bar_positions = np.arange(len(result.exceedance_probability))*0.5\n",
    "    ax.bar(bar_positions, result.exceedance_probability, color=colors, width=0.4)\n",
    "    # plt.legend(fontsize=FONTSIZE, frameon=False)\n",
    "    ax.set_xlabel('Models', fontsize=FONTSIZE)\n",
    "    # ax.set_ylim(0, 0.7)\n",
    "    ax.set_ylabel('Exceedance probability', fontsize=FONTSIZE) \n",
    "    ax.set_xticks(bar_positions)  # Set x-tick positions to bar_positions\n",
    "    ax.set_xticklabels(models, fontsize=FONTSIZE-2)  # Assign category names to x-tick labels\n",
    "    plt.yticks(fontsize=FONTSIZE-2)\n",
    "\n",
    "ax.set_title(f'Model Comparison', fontsize=FONTSIZE)\n",
    "sns.despine()\n",
    "f.tight_layout()\n",
    "# f.savefig(f'{SYS_PATH}/figures/exceedance_probability_{task_name}.svg', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469f42c-873d-4af9-b149-741e7b9aa968",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.protected_exceedance_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725f1f4c-2208-46c8-a2ab-7b3397b7a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.exceedance_probability, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e73bf2-91cb-4d38-98ef-b1d3fbaad132",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mean_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec00820-afb8-4d87-b1f2-7f07ef4c18e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## six rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f29afeb-be93-4ed5-8230-42c69c6dce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c0fcb-2446-4475-92c5-4d8c07cd0b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = pd.read_csv('../categorisation/data/llm/shepard1961_llm_choices_match_ermi.csv')\n",
    "categories = {'j': 'A', 'f': 'B'}\n",
    "datas['human_category']=datas['choice'].map(categories)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a775da94-4247-4d37-ac2d-11d0f7ec7081",
   "metadata": {},
   "source": [
    "datas"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1e0f753-0c6e-48fe-a4fe-e30fb95f24d5",
   "metadata": {},
   "source": [
    "load_data = pd.read_csv('../categorisation/data/human/badham2017deficitsllm_choiceshuman_allparticipants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb141a4a-1b43-46e5-b5eb-c49e6b5ea6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_participants = 94\n",
    "num_rules = 6\n",
    "num_block = 6\n",
    "correct = np.ones((num_rules, num_participants, 96))\n",
    "human_correct = np.ones((num_rules, num_participants, 96))\n",
    "block_errors = np.ones((num_rules, num_block))\n",
    "\n",
    "datas = pd.read_csv('../categorisation/data/llm/shepard1961_llm_choices_match_ermi.csv')\n",
    "categories = {'j': 'A', 'f': 'B'}\n",
    "datas['human_category']=datas['choice'].map(categories)\n",
    "\n",
    "\n",
    "for participant_id  in range(num_participants):#= 4\n",
    "    for cond in datas.condition.unique(): #datas.condition.nunique()):\n",
    "        if cond<=4:\n",
    "            load_data = pd.read_csv('../categorisation/data/llm/badham2017deficits_llm_choicesmatch_ermi.csv')\n",
    "        else:\n",
    "            load_data = pd.read_csv('../categorisation/data/llm/shepard1961_llm_choices_match_ermi.csv')\n",
    "        data = load_data[load_data.condition==cond]\n",
    "        correct_trials = data[data.participant==participant_id].llm_category.values==data[data.participant==participant_id].true_category.values\n",
    "        # print(len(data[data.participant==participant_id]))\n",
    "        correct[cond-1, participant_id, :len(correct_trials)] = correct_trials\n",
    "        \n",
    "        human_correct_trials = data[data.participant==participant_id].choice.values==data[data.participant==participant_id].correct_choice.values\n",
    "        human_correct[cond-1, participant_id,:len(correct_trials)] = human_correct_trials\n",
    "        #plt.plot(data[data.participant==participant_id].llm_category.values==data[data.participant==participant_id].true_category.values\n",
    "\n",
    "for cond in datas.condition.unique():\n",
    "    block_errors[cond-1] = 1-correct[cond-1].mean(0).reshape(96//16, 16).mean(1)\n",
    "np.savez(f'{SYS_PATH}/categorisation/data/stats/shepard1961_llm_simulations.npz', block_errors=block_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb4f443-de84-4aa2-976f-4abecda4a708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22527dd-603d-4990-8620-5f65b9a84163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e1848a-0faf-4239-9c0c-a0b246eb661e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa2f4c-a26f-4acb-8263-54fa4b5adb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for cond in range(datas.condition.nunique()):\n",
    "    plt.plot(1-correct[cond].mean(0), label = [\"Type ONE\", \"Type TWO\", \"Type THREE\", \"Type FOUR\", \"Type FIVE\", \"Type SIX\"][cond])\n",
    "plt.title(\"Claude's simulations\", fontsize=16)\n",
    "plt.xlabel(\"Trials\", fontsize=14)\n",
    "plt.ylabel(\"Mean error\", fontsize=14)\n",
    "plt.legend(frameon=False)#, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a6a1e2-0d3c-461b-9fa8-8128449fcaa2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "8feaf07d-3e3a-4fbd-84a5-1b67dce29f7b",
   "metadata": {},
   "source": [
    "import json\n",
    "# load json file containing the data\n",
    "SYS_PATH = '/u/ajagadish/ermi/'\n",
    "with open(f'{SYS_PATH}/categorisation/data/human/nosofsky1994.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "mse_distance = np.zeros((10, 1))\n",
    "aa = []\n",
    "for idx, eps in enumerate([0.]):#np.arange(0, 1, 0.1)\n",
    "    for t_idx, rule in enumerate(data.keys()):\n",
    "        block_errors = 1-correct[t_idx].mean(0).reshape(96//16, 16).mean(1) + eps\n",
    "        human_block_error = data[rule]['y'][:(96//16)]\n",
    "        aa.append(human_block_error)\n",
    "        # compute mse between human and model error rates for a model summed across tasks\n",
    "        mse_distance[idx] += np.mean((block_errors-human_block_error)**2)\n",
    "        print(f\"eps: {eps}, rule: {rule}, mse: {np.mean((block_errors-human_block_error)**2)}\") "
   ]
  },
  {
   "cell_type": "raw",
   "id": "82065d1d-59f4-495c-a669-efcd3561a7eb",
   "metadata": {},
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a83b9c02-d96b-40ba-8128-8d5781eb07be",
   "metadata": {},
   "source": [
    "ermi = [0.09118815, 0.13745117, 0.13166992, 0.12476562, 0.13608724, 0.17980143]\n",
    "mi = [0.09587565, 0.43374674, 0.26553385, 0.16566406, 0.31748047, 0.43873698]\n",
    "rmc = [0.15931641, 0.274375, 0.23145508 ,0.21645182, 0.25762695, 0.38454102]\n",
    "pfn = [0.04015625, 0.39083008, 0.18872396, 0.05267253, 0.27216471, 0.42367839]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b3739-9c94-4270-9aab-ab11b62f70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# datas = pd.read_csv('../categorisation/data/human/badham2017deficitsllm_choiceshuman_allparticipants.csv')\n",
    "datas = pd.read_csv('../categorisation/data/llm/shepard1961_llm_choices_match_ermi.csv')\n",
    "models = ['LLM']\n",
    "FONTSIZE=20\n",
    "f, axes = plt.subplots(1, len(models), figsize=(6*len(models), 5))\n",
    "colors = ['#E0E1DD', '#B6B9B9', '#8C9295', '#616A72','#37434E','#0D1B2A']\n",
    "# markers for the six types of rules in the plot: circle, cross, plus, inverted triangle, asterisk, triangle\n",
    "markers = ['o', 'x', '+', '*', 'v', '^']\n",
    "num_blocks = 6\n",
    "for idx, ax in enumerate([axes]):\n",
    "\n",
    "    for cond in range(datas.condition.nunique()):\n",
    "        mean_cond = 1-correct[cond].mean(0).reshape(96//16, 16).mean(1) #+ 0.1\n",
    "        std_cond = correct[cond].std(0).reshape(96//16, 16).mean(1)/np.sqrt(num_participants)\n",
    "        ax.plot(np.arange(96//16)+1, mean_cond, label=f'Type {cond}', lw=3, color=colors[cond], marker=markers[cond], markersize=8)\n",
    "        print(f'mean error for type {cond}: {mean_cond.mean()}')   \n",
    "    if idx==0:\n",
    "        ax.set_title('LLM', fontsize=FONTSIZE)\n",
    "\n",
    "    ax.set_xticks(np.arange(1, num_blocks+1))\n",
    "    if idx==0:\n",
    "        ax.set_xlabel('Block', fontsize=FONTSIZE)\n",
    "        ax.set_ylabel('P(Error)', fontsize=FONTSIZE)\n",
    "    ax.set_ylim([-0.01, .55])\n",
    "    # locs, labels = ax.get_xticks(), ax.get_xticklabels()\n",
    "    # Set new x-tick locations and labels\n",
    "    ax.set_xticks(np.arange(1, num_blocks+1)[::2])\n",
    "    ax.set_xticklabels(np.arange(1, num_blocks+1)[::2], fontsize=FONTSIZE-2)\n",
    "    ax.tick_params(axis='y', labelsize=FONTSIZE-2)       \n",
    "\n",
    "# add legend that spans across all subplots, in one row, at the center for the subplots, and place it outside the plot \n",
    "# f.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=6, fontsize=FONTSIZE-2, frameon=False, labels=[f'TYPE {task}' for task in tasks])\n",
    "sns.despine()\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ae515f-bf6b-4e74-a42e-5d66115b11c2",
   "metadata": {},
   "source": [
    "## smith and tassk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753a77f7-df1d-434e-8e52-cf4f2d79d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = pd.read_csv('../categorisation/data/human/devraj2022rationalllm_choiceshuman.csv')\n",
    "# find the unique true_category in each participant \n",
    "unique_categories = datas.groupby('participant')['true_category'].unique()\n",
    "# print(unique_categories)\n",
    "for participant_id in datas.participant.unique()[:16]:\n",
    "    datas.loc[datas.participant==participant_id, 'true_category'] = datas.loc[datas.participant==participant_id, 'true_category'].map({unique_categories[participant_id][0]: 0, unique_categories[participant_id][1]: 1})\n",
    "    datas.loc[datas.participant==participant_id, 'llm_category'] = datas.loc[datas.participant==participant_id, 'llm_category'].map({unique_categories[participant_id][0]: 0, unique_categories[participant_id][1]: 1})\n",
    "# datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91304b96-c99d-4c12-a019-02c3975805e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_participants = 16 #datas.participant.max()\n",
    "correct = np.ones((1, num_participants, 616))\n",
    "human_correct = np.ones((1, num_participants, 616))\n",
    "\n",
    "for participant_id  in range(num_participants):#= 4\n",
    "    for cond in ['control']: #datas.condition.nunique()):\n",
    "        data = datas[datas.condition==cond]\n",
    "        correct_trials = data[data.participant==participant_id].llm_category.values==data[data.participant==participant_id].true_category.values\n",
    "        correct[0, participant_id, :len(correct_trials)] = correct_trials\n",
    "        \n",
    "        human_correct_trials = data[data.participant==participant_id].choice.values==data[data.participant==participant_id].correct_choice.values\n",
    "        human_correct[0, participant_id,:len(correct_trials)] = human_correct_trials\n",
    "        #plt.plot(data[data.participant==participant_id].llm_category.values==data[data.participant==participant_id].true_category.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24ff69-ecdb-474f-a12b-0850235bbb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a27fe7-28cb-45b3-9da7-13cd28b0bf8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "# for cond in range(datas.condition.nunique()):\n",
    "#     plt.plot(1-correct[0].mean(0))\n",
    "mean_cond = 1-correct[0].mean(0).reshape(616//56, 56).mean(1)\n",
    "std_cond = correct[0].std(0).reshape(616//56, 56).mean(1)/np.sqrt(num_participants)\n",
    "plt.errorbar(np.arange(616//56)+1, mean_cond, yerr=std_cond)\n",
    "plt.title(\"LLM on Devraj task\", fontsize=16)\n",
    "plt.xlabel(\"Block\", fontsize=14)\n",
    "plt.ylabel(\"Mean error\", fontsize=14)\n",
    "plt.legend(frameon=False)#, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f9f53-cb3e-40aa-a87f-9f4c4fe981d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9843ca75-6b0b-43a2-830f-1682a790ffa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "760e8e12-65b7-4028-89f9-619d79a00b31",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88c5224c-785a-4cc2-8a06-b742467d861e",
   "metadata": {},
   "source": [
    "## four rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616677c-2fe3-4e2b-98b1-373ffbc510f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "datas = pd.read_csv('../categorisation/data/llm/badham2017deficits_llm_choicesmatch_ermi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443d0c90-5171-4882-920a-17c776833b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {'j': 'A', 'f': 'B'}\n",
    "datas['human_category']=datas['choice'].map(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e52310-7fa0-4ffe-9b3c-323c8ae244bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_participants = 94\n",
    "correct = np.ones((4, num_participants, 96))\n",
    "human_correct = np.ones((4, num_participants, 96))\n",
    "\n",
    "for participant_id  in range(num_participants):#= 4\n",
    "    for cond in datas.condition.unique(): #datas.condition.nunique()):\n",
    "        data = datas[datas.condition==cond]\n",
    "        correct_trials = data[data.participant==participant_id].llm_category.values==data[data.participant==participant_id].true_category.values\n",
    "        correct[cond-1, participant_id, :len(correct_trials)] = correct_trials\n",
    "        human_correct_trials = data[data.participant==participant_id].choice.values==data[data.participant==participant_id].correct_choice.values\n",
    "        human_correct[cond-1, participant_id,:len(correct_trials)] = human_correct_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec76c11-a76c-4bfa-88ea-e9c774966f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e20bbe-74dd-432e-af1a-89444da981a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2845d89-ad75-4cde-b95a-0c3e18c03ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for cond in range(datas.condition.nunique()):\n",
    "    plt.plot(1-correct[cond].mean(0), label = [\"Type ONE\", \"Type TWO\", \"Type THREE\", \"Type FOUR\"][cond])\n",
    "plt.title(\"Claude's simulations\", fontsize=16)\n",
    "plt.xlabel(\"Trials\", fontsize=14)\n",
    "plt.ylabel(\"Mean error\", fontsize=14)\n",
    "plt.legend(frameon=False)#, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba1b82-1aea-4ecb-8123-3d0f94b77767",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91804b92-e166-4019-9b02-42d61d88da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct[cond].mean(0).reshape(96//16, 16).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84f4a45-35a8-48f5-8048-dcb95a2d1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "models = ['LLM', None]\n",
    "FONTSIZE=20\n",
    "f, axes = plt.subplots(1, len(models), figsize=(6*len(models), 5))\n",
    "colors = ['#E0E1DD', '#B6B9B9', '#8C9295', '#616A72','#37434E','#0D1B2A']\n",
    "# markers for the six types of rules in the plot: circle, cross, plus, inverted triangle, asterisk, triangle\n",
    "markers = ['o', 'x', '+', '*', 'v', '^']\n",
    "num_blocks = 6\n",
    "for idx, ax in enumerate(axes):\n",
    "\n",
    "    for cond in range(datas.condition.nunique()):\n",
    "        mean_cond = 1-correct[cond].mean(0).reshape(96//16, 16).mean(1)\n",
    "        std_cond = correct[cond].std(0).reshape(96//16, 16).mean(1)/np.sqrt(num_participants)\n",
    "        ax.plot(np.arange(96//16)+1, mean_cond, label=f'Type {cond}', lw=3, color=colors[cond], marker=markers[cond], markersize=8)\n",
    "\n",
    "    if idx==0:\n",
    "        ax.set_title('LLM', fontsize=FONTSIZE)\n",
    "\n",
    "    ax.set_xticks(np.arange(1, num_blocks+1))\n",
    "    if idx==0:\n",
    "        ax.set_xlabel('Block', fontsize=FONTSIZE)\n",
    "        ax.set_ylabel('P(Error)', fontsize=FONTSIZE)\n",
    "    ax.set_ylim([-0.01, .55])\n",
    "    # locs, labels = ax.get_xticks(), ax.get_xticklabels()\n",
    "    # Set new x-tick locations and labels\n",
    "    ax.set_xticks(np.arange(1, num_blocks+1)[::2])\n",
    "    ax.set_xticklabels(np.arange(1, num_blocks+1)[::2], fontsize=FONTSIZE-2)\n",
    "    ax.tick_params(axis='y', labelsize=FONTSIZE-2)       \n",
    "\n",
    "# add legend that spans across all subplots, in one row, at the center for the subplots, and place it outside the plot \n",
    "# f.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=6, fontsize=FONTSIZE-2, frameon=False, labels=[f'TYPE {task}' for task in tasks])\n",
    "sns.despine()\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd7362-ef4d-4e51-81ef-accc92c72ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1d33d-9a77-4877-a3e9-541ddc799572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for cond in range(datas.condition.nunique()):\n",
    "    mean_cond = 1-correct[cond].mean(0).reshape(96//16, 16).mean(1)\n",
    "    std_cond = correct[cond].std(0).reshape(96//16, 16).mean(1)/np.sqrt(num_participants)\n",
    "    plt.errorbar(np.arange(96//16)+1, mean_cond, yerr=std_cond, label = [\"Type ONE\", \"Type TWO\", \"Type THREE\", \"Type FOUR\"][cond])\n",
    "plt.title(\"Claude's simulations\", fontsize=16)\n",
    "plt.xlabel(\"Blocks\", fontsize=14)\n",
    "plt.ylabel(\"Mean error\", fontsize=14)\n",
    "plt.legend(frameon=False)#, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9142d02a-8aed-4ab4-9e2b-bbad9d23772b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "6fdbee6e-266b-40f1-9983-e68594137006",
   "metadata": {
    "tags": []
   },
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for cond in range(datas.condition.nunique()):\n",
    "    plt.plot(1-human_correct[cond].mean(0), label = [\"Type ONE\", \"Type TWO\", \"Type THREE\", \"Type FOUR\"][cond])\n",
    "plt.title(\"Human choices simulations\", fontsize=16)\n",
    "plt.xlabel(\"Trials\", fontsize=14)\n",
    "plt.ylabel(\"Mean error\", fontsize=14)\n",
    "plt.legend(frameon=False)#, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b78d50-3023-42b3-849f-c0cd86946a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f38888-a716-48f2-a49f-e4efe8edcdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column to the dataframe when llm_category is same as true_category\n",
    "data['correct'] = data['llm_category'] == data['true_category']\n",
    "# plot correct averaged over participants for condition == 1 over time\n",
    "data.groupby('trial')['correct'].mean().plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6998850d-c92b-4946-abf4-0474425fede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9d8ce-01bc-467a-adf5-affe64f89857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[data.participant.isin(data.participant.unique())]#==data[data.participant.isin(data.participant.unique())].true_category.values # ==data[data.participant.isin(data.participant.unique())].true_category.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639c0c23",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72c630-7629-4391-bdb5-318e8adfedc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df_grouped.accuracy[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31051034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2239095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4644de2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44413c01-6973-4af7-97ba-5c91cf712ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_id = 90\n",
    "num_trials = 400\n",
    "plt.plot((data[data.participant==participant_id].llm_category.values==data[data.participant==participant_id].true_category.values)[:num_trials])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba21df-1d17-4e5e-84c0-61b21db088ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ef501-777a-44cf-aeb6-21e758e4e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data[data.participant==0].llm_category[:56].values==data[data.participant==0].true_category[:56].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76ebae0-e2ae-4484-9846-1dd22e6cb073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
